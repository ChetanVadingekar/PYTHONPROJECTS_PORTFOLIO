I have an API and their utility functions see below,

@app.route("/get-project-details", methods=["GET"])
def fetch_projects_info() -> ResponseReturnValue:
    """
    Get the projects information to render on home page.

    Returns:
        (ResponseReturnValue): list of events.
    """
    projection_attributes = [
        "project_name",
        "country_code",
        "generation_name",
        "model_name",
        "drive_session_table_name",
    ]
    try:
        response = lookup_table.scan(
            ProjectionExpression=",".join(projection_attributes)
        )

        projects = response.get("Items", [])

        while response.get("LastEvaluatedKey"):
            response = lookup_table.scan(
                ProjectionExpression=",".join(projection_attributes),
                ExclusiveStartKey=response["LastEvaluatedKey"],
            )
            if response.get("Items"):
                projects.extend(response.get("Items"))  # type: ignore

        if not projects:
            message = "No projects found in lookup table for home page listing"
            logging.info(message)
            return jsonify({"data": [], "message": message}), 200

        response_data = format_project_details(projects)

        return (
            jsonify(
                {
                    "data": response_data,
                    "message": "Fetched projects from lookup table",
                }
            ),
            200,
        )

    except ClientError as err:
        message = err.response['Error']['Message']
        code = err.response['Error']['Code']

        if code == "ResourceNotFoundException":
            message = f"DynamoDB Table {LOOKUP_TABLE} not found"
            logging.error(message)
            status_code = 404
        else:
            logging.error(f"Unhandled Exception: {code}:{message}")
            status_code = 500

        return jsonify({"message": message, "error_code": code}), status_code


def format_project_details(projects: list) -> list:
    """
    Rearrange the projects based on region.

    Args:
        projects (list): Lookup table project items

    Returns:
        list: Formatted project details
    """
    data: dict = {}
    for project in projects:
        name = project.get("project_name")
        country_code = project.get("country_code", "JP").upper()

        # if country_code is an empty string
        if not country_code:
            country_code = "JP"

        generation_name = project.get("generation_name", "Gen1").capitalize()
        model_name = project.get("model_name", "PADAS").upper()
        drive_session_table_name = project.get("drive_session_table_name","")
        version = f"Gen{generation_name} {model_name}"

        project_info = {
            "project_name": name, 
            "version": version, 
            "drive_session_table_name": drive_session_table_name
        }

        if country_code in data:
            data[country_code]["projects"].append(project_info)
        else:
            data[country_code] = {"projects": [project_info]}

    formatted_data = []
    for country in data:
        country_details = get_country_details(country_code=country)

        # Default setting the country_details to Japan
        country_name = country_details.get("country_name", "Japan")
        center_point = country_details.get(
            "center_point", ["36.204824", "138.252924"]
        )
        data_dict = {
            "country": country_name,
            "latlng": center_point,
            "projects": data[country]["projects"],
        }
        formatted_data.append(data_dict)

    return formatted_data

def get_country_details(country_code: str) -> dict:
    """
    Fetch country details for map centering.

    Args:
        country_code: Unique code of the country

    Returns:
        dict: Details for map centering
            country_code: Unique code of the country
            country_name: Name of the country
            center_point: List of latitude and longitude of the country
            zoom_level: Zoom level to be used for displaying on dashboard
    """
    map_details: dict = {}
    try:
        response = map_info_table.query(
            KeyConditionExpression=Key('country_code').eq(country_code)
        )

        map_details = response["Items"][0]

    except IndexError as e:
        logging.info(f"No records found: {str(e)}")

    except exceptions.ClientError as error:
        message = error.response['Error']['Message']
        code = error.response['Error']['Code']

        if code == "ResourceNotFoundException":
            logging.error(
                f"DynamoDB Table {MAP_INFO_TABLE_NAME} not found: {str(error)}"
            )
        else:
            logging.error(f"Unhandled Exception: {code}{message}")

    return map_details


Now the requiremnt is client want to see rec_year_month_date as well.
so what we thought we get the drive session table name for each project and we have OpenSearch index for ecah drive session table name.
so using that drive session table name we can query on OpenSearch to find out the rec_year_month_date.

FY reference we have OpenSearch schema for the drive sessions index see below,

class DriveSession(Document):
    """Document to store Drive Session data."""

    created_at = Date()
    display_id = Keyword()
    folder_name = Keyword()
    gps_information = Object(dynamic=True)  # type: ignore
    rec_year_month = Keyword()
    rec_year_month_date = Keyword()
    s3_uri = Object(dynamic=True)  # type: ignore
    start_time = Date()
    stop_time = Date()
    tags = Keyword(multi=True, normalizer="lowercase")  # type: ignore
    updated_at = Date()
    vehicle_id = Keyword()
    trajectory = Object(dynamic=True)  # type: ignore
    current_status = Keyword()
    pipeline_status = Object(dynamic=True)  # type: ignore
    
FY reference see some data present in the the drive sessions index for each project drive session table name

      {
        "_index": "adcp-us-project-01-drive-data",
        "_id": "41-20220323_141245",
        "_score": 1,
        "_source": {
          "country": "US",
          "updated_at": "2024-07-10T05:04:37.422827",
          "display_id": "901e2beb-bc26-42dd-91dd-97300c3cff6d",
          "rec_year_month": "202203",
          "created_at": "2024-07-10T05:02:10.972604+00:00",
          "current_status": "Failed",
          "pipeline_status": {
            "merge_avi": {
              "error_log_name": [
                "/aws/batch/job|dev-DataMerge-MergeAVI/default/1c0474f86224411994294615cbe12c90"
              ],
              "updated_at": "2024-07-10T05:04:37.422378",
              "status": "Failed"
            },
            "merge_parquet": {
              "error_log_name": [],
              "updated_at": "2024-07-10T05:02:10.972604+00:00",
              "status": "Pending"
            },
            "upload": {
              "error_log_name": [],
              "updated_at": "2024-07-10T05:03:47.825305+00:00",
              "status": "Completed"
            },
            "rosbag": {
              "error_log_name": [],
              "updated_at": "2024-07-10T05:02:10.972604+00:00",
              "status": "Pending"
            },
            "conversion": {
              "error_log_name": "",
              "updated_at": "2024-07-10T05:03:47.825305+00:00",
              "status": "InProgress"
            },
            "statistics": {
              "error_log_name": [],
              "updated_at": "2024-07-10T05:02:10.972604+00:00",
              "status": "Pending"
            }
          },
          "folder_name": "20220323_141245",
          "rec_year_month_date": "20220323",
          "vehicle_id": "41"
        }
      },
      {
        "_index": "adcp-us-project-01-drive-data",
        "_id": "41-20220323_213053",
        "_score": 1,
        "_source": {
          "country": "US",
          "updated_at": "2024-07-10T05:05:00.287609",
          "display_id": "6fd0ffc8-80bb-4e4d-af13-e4e284931a06",
          "rec_year_month": "202203",
          "created_at": "2024-07-10T05:03:50.107545+00:00",
          "current_status": "Failed",
          "pipeline_status": {
            "merge_avi": {
              "error_log_name": [
                "/aws/batch/job|dev-DataMerge-MergeAVI/default/db006b84906045f699bfb2bcb320fc07"
              ],
              "updated_at": "2024-07-10T05:05:00.287180",
              "status": "Failed"
            },
            "merge_parquet": {
              "error_log_name": [],
              "updated_at": "2024-07-10T05:03:50.107545+00:00",
              "status": "Pending"
            },
            "upload": {
              "error_log_name": [],
              "updated_at": "2024-07-10T05:04:30.979145+00:00",
              "status": "Completed"
            },
            "rosbag": {
              "error_log_name": [],
              "updated_at": "2024-07-10T05:03:50.107545+00:00",
              "status": "Pending"
            },
            "conversion": {
              "error_log_name": "",
              "updated_at": "2024-07-10T05:04:30.979145+00:00",
              "status": "InProgress"
            },
            "statistics": {
              "error_log_name": [],
              "updated_at": "2024-07-10T05:03:50.107545+00:00",
              "status": "Pending"
            }
          },
          "folder_name": "20220323_213053",
          "rec_year_month_date": "20220323",
          "vehicle_id": "41"
        }
      },

so we have to write a query to get rec_year_month_date for the respective drive sessions index for each project.
once we get the rec_year_month_date for each projects then we have to format in the YYYY-DD-MM format and send it in the response.  
